{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DC024</th>\n",
       "      <th>DC025</th>\n",
       "      <th>DC205</th>\n",
       "      <th>DC206</th>\n",
       "      <th>DC207</th>\n",
       "      <th>DC208</th>\n",
       "      <th>DC209</th>\n",
       "      <th>DC210</th>\n",
       "      <th>DC211</th>\n",
       "      <th>DC212</th>\n",
       "      <th>...</th>\n",
       "      <th>DC237f</th>\n",
       "      <th>DC241</th>\n",
       "      <th>DC242</th>\n",
       "      <th>DC244</th>\n",
       "      <th>DC246</th>\n",
       "      <th>DC252</th>\n",
       "      <th>DC270a</th>\n",
       "      <th>DC109</th>\n",
       "      <th>DC142a</th>\n",
       "      <th>DC201</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.060120</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.226190</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.070140</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.075150</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.085170</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.065130</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64791</th>\n",
       "      <td>0.768709</td>\n",
       "      <td>0.399038</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.600962</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.399038</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.600962</td>\n",
       "      <td>0.650240</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.148711</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64792</th>\n",
       "      <td>0.602410</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.913505</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.086495</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.086495</td>\n",
       "      <td>0.086495</td>\n",
       "      <td>0.314871</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.032324</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64793</th>\n",
       "      <td>0.605577</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.012520</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032865</td>\n",
       "      <td>0.052584</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.003093</td>\n",
       "      <td>0.080372</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64794</th>\n",
       "      <td>0.036779</td>\n",
       "      <td>0.508774</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.508774</td>\n",
       "      <td>0.508774</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.101755</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.508774</td>\n",
       "      <td>0.495613</td>\n",
       "      <td>0.381580</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.084168</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64795</th>\n",
       "      <td>0.275121</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.417501</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.417501</td>\n",
       "      <td>0.417501</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.116500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.686874</td>\n",
       "      <td>0.208751</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.171994</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64796 rows Ã— 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          DC024     DC025     DC205     DC206  DC207     DC208     DC209   \n",
       "0      0.000000  1.000000  0.047619  1.000000    0.0  1.000000  0.000000  \\\n",
       "1      0.000000  1.000000  0.226190  1.000000    0.0  1.000000  0.000000   \n",
       "2      0.000000  1.000000  0.000000  1.000000    0.0  1.000000  1.000000   \n",
       "3      0.000000  1.000000  0.000000  1.000000    0.0  0.000000  0.000000   \n",
       "4      0.000000  1.000000  0.000000  1.000000    0.0  1.000000  1.000000   \n",
       "...         ...       ...       ...       ...    ...       ...       ...   \n",
       "64791  0.768709  0.399038  0.000000  1.000000    0.0  1.000000  1.000000   \n",
       "64792  0.602410  1.000000  1.000000  0.913505    0.0  0.086495  0.000000   \n",
       "64793  0.605577  1.000000  0.012520  1.000000    0.0  1.000000  0.000000   \n",
       "64794  0.036779  0.508774  0.047619  1.000000    0.0  1.000000  0.508774   \n",
       "64795  0.275121  1.000000  0.107143  1.000000    0.0  0.417501  0.000000   \n",
       "\n",
       "          DC210     DC211     DC212  ...    DC237f     DC241     DC242   \n",
       "0      0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  \\\n",
       "1      0.000000  1.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "2      1.000000  1.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "3      0.000000  1.000000  0.000000  ...  0.000000  0.200000  1.000000   \n",
       "4      0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "64791  0.000000  1.000000  0.600962  ...  0.000000  0.000000  0.399038   \n",
       "64792  0.000000  0.000000  0.000000  ...  0.000000  0.000000  1.000000   \n",
       "64793  0.000000  1.000000  0.000000  ...  0.032865  0.052584  1.000000   \n",
       "64794  0.508774  1.000000  0.000000  ...  0.000000  0.101755  1.000000   \n",
       "64795  0.417501  0.417501  0.000000  ...  0.000000  0.116500  1.000000   \n",
       "\n",
       "          DC244     DC246     DC252    DC270a     DC109    DC142a  DC201  \n",
       "0      0.000000  0.000000  0.500000  0.000000  0.011765  0.060120    1.0  \n",
       "1      1.000000  1.000000  0.250000  0.250000  0.235294  0.070140    1.0  \n",
       "2      1.000000  1.000000  0.000000  0.750000  0.000000  0.075150    1.0  \n",
       "3      1.000000  0.000000  0.250000  0.000000  0.000000  0.085170    1.0  \n",
       "4      0.000000  1.000000  0.000000  0.250000  0.000000  0.065130    1.0  \n",
       "...         ...       ...       ...       ...       ...       ...    ...  \n",
       "64791  1.000000  1.000000  0.600962  0.650240  0.000000  0.148711    0.0  \n",
       "64792  0.086495  0.086495  0.314871  0.000000  1.000000  0.032324    0.0  \n",
       "64793  1.000000  1.000000  0.250000  0.250000  0.003093  0.080372    0.0  \n",
       "64794  1.000000  0.508774  0.495613  0.381580  0.011765  0.084168    0.0  \n",
       "64795  0.000000  1.000000  0.686874  0.208751  0.352941  0.171994    0.0  \n",
       "\n",
       "[64796 rows x 39 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('./train_scaled_null_balance_minmax.csv')\n",
    "data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into train and test for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51836, 38)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Split dataset menjadi training dan testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(data.drop('DC201',axis=1),data['DC201'],test_size=0.2)\n",
    "input_shape=(x_train.shape)\n",
    "input_shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train data using various algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train using Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9438271604938272 F1 Score  0.9449235890452413\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0    0.96254   0.92363   0.94269      6482\n",
      "         1.0    0.92656   0.96403   0.94492      6478\n",
      "\n",
      "    accuracy                        0.94383     12960\n",
      "   macro avg    0.94455   0.94383   0.94380     12960\n",
      "weighted avg    0.94455   0.94383   0.94380     12960\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# Define Gradient Boosting model\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "\n",
    "# Train model\n",
    "gb_model.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions on test set\n",
    "y_pred = gb_model.predict(x_test)\n",
    "\n",
    "# Calculate accuracy score\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1=f1_score(y_test, y_pred)\n",
    "print('Accuracy:', acc, 'F1 Score ',f1)\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(y_test, y_pred,digits=5)\n",
    "\n",
    "# Print the classification report\n",
    "print(report)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train for scaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9438271604938272 F1 Score  0.9449235890452413\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.92      0.94      6482\n",
      "         1.0       0.93      0.96      0.94      6478\n",
      "\n",
      "    accuracy                           0.94     12960\n",
      "   macro avg       0.94      0.94      0.94     12960\n",
      "weighted avg       0.94      0.94      0.94     12960\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# Define Gradient Boosting model\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "\n",
    "# Train model\n",
    "gb_model.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions on test set\n",
    "y_pred = gb_model.predict(x_test)\n",
    "\n",
    "# Calculate accuracy score\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1=f1_score(y_test, y_pred)\n",
    "print('Accuracy:', acc, 'F1 Score ',f1)\n",
    "# Generate classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print the classification report\n",
    "print(report)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train using Light GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "{'lambda_l1': 0, 'lambda_l2': 0, 'max_bin': 35, 'min_data_in_leaf': 30, 'num_leaves': 108, 'reg_alpha': 0.1} 0.9546261240260228\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0    0.98559   0.91824   0.95072      6482\n",
      "         1.0    0.92342   0.98657   0.95395      6478\n",
      "\n",
      "    accuracy                        0.95239     12960\n",
      "   macro avg    0.95451   0.95240   0.95234     12960\n",
      "weighted avg    0.95452   0.95239   0.95234     12960\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold,GridSearchCV\n",
    "from lightgbm import LGBMClassifier\n",
    "gkf = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "param_grid = {\n",
    "    'lambda_l1': [0], 'lambda_l2': [0], 'min_data_in_leaf': [30], 'num_leaves': [108], 'reg_alpha': [0.1], 'max_bin':[35]\n",
    "    }\n",
    "            \n",
    "lgbm = LGBMClassifier(boosting_type='dart', n_estimators=1000, subsample=0.8,\n",
    "                      colsample_bytree=0.8, scale_pos_weight=2, num_leaves=100,\n",
    "                      random_state=42, learning_rate=0.1, min_child_weight=2, max_depth=22)\n",
    "gsearch = GridSearchCV(estimator=lgbm, param_grid=param_grid, cv=gkf)\n",
    "gsearch_res= gsearch.fit(x_train, y_train)\n",
    "print(gsearch_res.best_params_, gsearch_res.best_score_)\n",
    "prediction = gsearch_res.predict(x_test)\n",
    "print(classification_report(y_test, prediction, digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 300}\n",
      "Best Score: 0.9540473738042244\n",
      "Accuracy: 0.9522376543209876\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0    0.98065   0.92271   0.95080      6482\n",
      "         1.0    0.92698   0.98178   0.95359      6478\n",
      "\n",
      "    accuracy                        0.95224     12960\n",
      "   macro avg    0.95382   0.95225   0.95220     12960\n",
      "weighted avg    0.95382   0.95224   0.95220     12960\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create an instance of the LGBMClassifier\n",
    "lgbm = LGBMClassifier()\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.1, 0.01, 0.001],\n",
    "    'n_estimators': [100, 200, 300]\n",
    "}\n",
    "\n",
    "# Create an instance of GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=lgbm, param_grid=param_grid, cv=5)\n",
    "\n",
    "# Fit the model to the data\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)\n",
    "\n",
    "# Make predictions on the test data using the best model\n",
    "y_pred = grid_search.predict(x_test)\n",
    "\n",
    "# Calculate the accuracy of the best model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(classification_report(y_test, y_pred, digits=5))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train for scaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011005 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Accuracy: 0.9488425925925926\n",
      "F1 Score: 0.950214012164902\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0    0.97533   0.92101   0.94739      6482\n",
      "         1.0    0.92514   0.97669   0.95021      6478\n",
      "\n",
      "    accuracy                        0.94884     12960\n",
      "   macro avg    0.95023   0.94885   0.94880     12960\n",
      "weighted avg    0.95024   0.94884   0.94880     12960\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Booster at 0x1aa82b6dc40>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "# Create LightGBM dataset\n",
    "train_data = lgb.Dataset(x_train, label=y_train)\n",
    "\n",
    "# Set the hyperparameters for LightGBM\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "# Train the model\n",
    "model = lgb.train(params, train_data, num_boost_round=100)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Convert probabilities to binary predictions\n",
    "y_pred_binary = [1 if pred >= 0.5 else 0 for pred in y_pred]\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred_binary)\n",
    "f1 = f1_score(y_test, y_pred_binary)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1 Score:\", f1)\n",
    "# Generate classification report\n",
    "report = classification_report(y_test, y_pred_binary,digits=5)\n",
    "\n",
    "# Print the classification report\n",
    "print(report)\n",
    "model.save_model('lgbm_final_1.json')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train using XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9527777777777777 F1 Score  0.9540747411076091\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0    0.98020   0.92425   0.95141      6482\n",
      "         1.0    0.92830   0.98132   0.95407      6478\n",
      "\n",
      "    accuracy                        0.95278     12960\n",
      "   macro avg    0.95425   0.95279   0.95274     12960\n",
      "weighted avg    0.95426   0.95278   0.95274     12960\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "# define xgboost model\n",
    "model = xgb.XGBClassifier(learning_rate=0.1,max_depth=6,n_estimators=300,subsample=0.9,colsample_bytree=0.8)\n",
    "\n",
    "# fit the model on the training set\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1=f1_score(y_test, y_pred)\n",
    "print('Accuracy:', acc, 'F1 Score ',f1)\n",
    "# Generate classification report\n",
    "report = classification_report(y_test, y_pred,digits=5)\n",
    "\n",
    "# Print the classification report\n",
    "print(report)\n",
    "model.save_model('xgboost_final_1.json')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train for scaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9527777777777777 F1 Score  0.9540057117090035\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0    0.97864   0.92579   0.95148      6482\n",
      "         1.0    0.92955   0.97978   0.95401      6478\n",
      "\n",
      "    accuracy                        0.95278     12960\n",
      "   macro avg    0.95410   0.95279   0.95274     12960\n",
      "weighted avg    0.95410   0.95278   0.95274     12960\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "# define xgboost model\n",
    "model = xgb.XGBClassifier(learning_rate=0.05,max_depth=7,n_estimators=1000,subsample=0.7,colsample_bytree=0.7)\n",
    "\n",
    "# fit the model on the training set\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1=f1_score(y_test, y_pred)\n",
    "print('Accuracy:', acc, 'F1 Score ',f1)\n",
    "# Generate classification report\n",
    "report = classification_report(y_test, y_pred,digits=5)\n",
    "\n",
    "# Print the classification report\n",
    "print(report)\n",
    "model.save_model('xgboost_final_2.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200, 'subsample': 0.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.953858024691358 F1 Score  0.955125318925409\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0    0.98135   0.92533   0.95252      6482\n",
      "         1.0    0.92932   0.98240   0.95513      6478\n",
      "\n",
      "    accuracy                        0.95386     12960\n",
      "   macro avg    0.95534   0.95387   0.95382     12960\n",
      "weighted avg    0.95534   0.95386   0.95382     12960\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "\n",
    "# define xgboost model\n",
    "model = xgb.XGBClassifier()\n",
    "\n",
    "# define hyperparameter grid for grid search\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.1, 0.3],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.5, 0.7],\n",
    "    'colsample_bytree': [0.5, 0.7],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "}\n",
    "\n",
    "# perform grid search to find the best hyperparameters\n",
    "grid_search = GridSearchCV(model, param_grid, scoring='accuracy', n_jobs=-1, cv=5)\n",
    "grid_result = grid_search.fit(x_train, y_train)\n",
    "\n",
    "# print the best hyperparameters\n",
    "print(\"Best parameters: \", grid_result.best_params_)\n",
    "\n",
    "# create a new model with the best hyperparameters\n",
    "model = xgb.XGBClassifier(**grid_result.best_params_)\n",
    "\n",
    "# fit the model on the training set\n",
    "model.fit(x_train, y_train, early_stopping_rounds=10, eval_metric='logloss', eval_set=[(x_test, y_test)], verbose=False)\n",
    "\n",
    "# make predi your target price\n",
    "# ctions on the test set\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# calculate accuracy of predictions\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1=f1_score(y_test, y_pred)\n",
    "print('Accuracy:', acc, 'F1 Score ',f1)\n",
    "# Generate classification report\n",
    "report = classification_report(y_test, y_pred,digits=5)\n",
    "\n",
    "# Print the classification report\n",
    "print(report)\n",
    "model.save_model('xgboost_final_3_grid.json')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train for scaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 300, 'subsample': 0.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9515432098765432 F1 Score  0.9529799341120095\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "\n",
    "# define xgboost model\n",
    "model = xgb.XGBClassifier()\n",
    "\n",
    "# define hyperparameter grid for grid search\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.1, 0.3],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.5, 0.7],\n",
    "    'colsample_bytree': [0.5, 0.7],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "}\n",
    "\n",
    "# perform grid search to find the best hyperparameters\n",
    "grid_search = GridSearchCV(model, param_grid, scoring='accuracy', n_jobs=-1, cv=5)\n",
    "grid_result = grid_search.fit(x_train, y_train)\n",
    "\n",
    "# print the best hyperparameters\n",
    "print(\"Best parameters: \", grid_result.best_params_)\n",
    "\n",
    "# create a new model with the best hyperparameters\n",
    "model = xgb.XGBClassifier(**grid_result.best_params_)\n",
    "\n",
    "# fit the model on the training set\n",
    "model.fit(x_train, y_train, early_stopping_rounds=10, eval_metric='logloss', eval_set=[(x_test, y_test)], verbose=False)\n",
    "\n",
    "# make predi your target price\n",
    "# ctions on the test set\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# calculate accuracy of predictions\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1=f1_score(y_test, y_pred)\n",
    "print('Accuracy:', acc, 'F1 Score ',f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train using Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.12%\n",
      "F1 Score: 93.12%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# define the AdaBoost model\n",
    "model = AdaBoostClassifier(n_estimators=50, random_state=42)\n",
    "\n",
    "# fit the model on the training set\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# calculate accuracy of predictions\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1=f1_score(y_test,y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "print(\"F1 Score: %.2f%%\" % (accuracy * 100.0))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
