{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import all needed Libraries/Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Read data, and then do some explanatory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DC024</th>\n",
       "      <th>DC025</th>\n",
       "      <th>DC205</th>\n",
       "      <th>DC206</th>\n",
       "      <th>DC207</th>\n",
       "      <th>DC208</th>\n",
       "      <th>DC209</th>\n",
       "      <th>DC210</th>\n",
       "      <th>DC211</th>\n",
       "      <th>DC212</th>\n",
       "      <th>...</th>\n",
       "      <th>DC237f</th>\n",
       "      <th>DC241</th>\n",
       "      <th>DC242</th>\n",
       "      <th>DC244</th>\n",
       "      <th>DC246</th>\n",
       "      <th>DC252</th>\n",
       "      <th>DC270a</th>\n",
       "      <th>DC109</th>\n",
       "      <th>DC142a</th>\n",
       "      <th>DC201</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64791</th>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.334627</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.665373</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.665373</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.334627</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>133.338509</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64792</th>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999670</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999670</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>71.999340</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64793</th>\n",
       "      <td>77</td>\n",
       "      <td>2</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.747717</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.252283</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.747717</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.747717</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.252283</td>\n",
       "      <td>1</td>\n",
       "      <td>31.252283</td>\n",
       "      <td>25.513698</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64794</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.184086</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.184086</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.815914</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>64.288604</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64795</th>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.144417</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.855583</td>\n",
       "      <td>0.144417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.144417</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.855583</td>\n",
       "      <td>0.855583</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>24.866504</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64796 rows Ã— 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       DC024  DC025  DC205     DC206     DC207     DC208     DC209     DC210   \n",
       "0         11      2   16.0  1.000000  0.000000  1.000000  0.000000  0.000000  \\\n",
       "1         11      2   31.0  1.000000  0.000000  1.000000  0.000000  0.000000   \n",
       "2         11      2   12.0  1.000000  0.000000  1.000000  1.000000  1.000000   \n",
       "3         11      2   12.0  1.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4         11      2   12.0  1.000000  0.000000  1.000000  1.000000  0.000000   \n",
       "...      ...    ...    ...       ...       ...       ...       ...       ...   \n",
       "64791     33      2   12.0  1.000000  0.334627  1.000000  0.665373  0.000000   \n",
       "64792     14      2   12.0  1.000000  0.000000  1.000000  0.000000  0.999670   \n",
       "64793     77      2   31.0  1.000000  0.747717  0.000000  0.000000  0.252283   \n",
       "64794     12      2   21.0  0.184086  0.000000  0.184086  0.000000  0.000000   \n",
       "64795     64      2   31.0  0.144417  0.000000  0.000000  0.000000  0.855583   \n",
       "\n",
       "          DC211  DC212  ...    DC237f  DC241     DC242     DC244     DC246   \n",
       "0      0.000000    0.0  ...  0.000000    1.0  0.000000  0.000000  0.000000  \\\n",
       "1      1.000000    0.0  ...  0.000000    1.0  0.000000  1.000000  1.000000   \n",
       "2      1.000000    0.0  ...  0.000000    1.0  0.000000  1.000000  1.000000   \n",
       "3      1.000000    0.0  ...  0.000000    2.0  1.000000  1.000000  0.000000   \n",
       "4      0.000000    0.0  ...  0.000000    1.0  0.000000  0.000000  1.000000   \n",
       "...         ...    ...  ...       ...    ...       ...       ...       ...   \n",
       "64791  1.000000    0.0  ...  0.665373    1.0  1.000000  1.000000  0.334627   \n",
       "64792  1.000000    0.0  ...  0.999670    1.0  1.000000  1.000000  1.000000   \n",
       "64793  0.000000    0.0  ...  0.747717    1.0  0.747717  1.000000  1.000000   \n",
       "64794  0.000000    0.0  ...  0.000000    1.0  1.000000  0.815914  0.000000   \n",
       "64795  0.144417    0.0  ...  0.144417    1.0  0.855583  0.855583  1.000000   \n",
       "\n",
       "          DC252  DC270a      DC109      DC142a  DC201  \n",
       "0      2.000000       1  12.000000   60.000000      0  \n",
       "1      1.000000       2  31.000000   70.000000      0  \n",
       "2      0.000000       4  11.000000   75.000000      0  \n",
       "3      1.000000       1  11.000000   85.000000      0  \n",
       "4      0.000000       2  11.000000   65.000000      0  \n",
       "...         ...     ...        ...         ...    ...  \n",
       "64791  1.000000       3  11.000000  133.338509      1  \n",
       "64792  1.000000       2  11.000000   71.999340      1  \n",
       "64793  0.252283       1  31.252283   25.513698      1  \n",
       "64794  1.000000       1  41.000000   64.288604      1  \n",
       "64795  1.000000       1  51.000000   24.866504      1  \n",
       "\n",
       "[64796 rows x 39 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('./data/clean.csv',header=0,index_col=0)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 64796 entries, 0 to 64795\n",
      "Data columns (total 39 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   DC024   64796 non-null  int64  \n",
      " 1   DC025   64796 non-null  int64  \n",
      " 2   DC205   64796 non-null  float64\n",
      " 3   DC206   64796 non-null  float64\n",
      " 4   DC207   64796 non-null  float64\n",
      " 5   DC208   64796 non-null  float64\n",
      " 6   DC209   64796 non-null  float64\n",
      " 7   DC210   64796 non-null  float64\n",
      " 8   DC211   64796 non-null  float64\n",
      " 9   DC212   64796 non-null  float64\n",
      " 10  DC213   64796 non-null  float64\n",
      " 11  DC214   64796 non-null  float64\n",
      " 12  DC215   64796 non-null  float64\n",
      " 13  DC216   64796 non-null  float64\n",
      " 14  DC217   64796 non-null  int64  \n",
      " 15  DC219   64796 non-null  int64  \n",
      " 16  DC220   64796 non-null  float64\n",
      " 17  DC226   64796 non-null  float64\n",
      " 18  DC230a  64796 non-null  float64\n",
      " 19  DC230b  64796 non-null  float64\n",
      " 20  DC232   64796 non-null  float64\n",
      " 21  DC232b  64796 non-null  float64\n",
      " 22  DC235   64796 non-null  float64\n",
      " 23  DC237   64796 non-null  float64\n",
      " 24  DC237a  64796 non-null  float64\n",
      " 25  DC237b  64796 non-null  float64\n",
      " 26  DC237c  64796 non-null  float64\n",
      " 27  DC237d  64796 non-null  float64\n",
      " 28  DC237e  64796 non-null  float64\n",
      " 29  DC237f  64796 non-null  float64\n",
      " 30  DC241   64796 non-null  float64\n",
      " 31  DC242   64796 non-null  float64\n",
      " 32  DC244   64796 non-null  float64\n",
      " 33  DC246   64796 non-null  float64\n",
      " 34  DC252   64796 non-null  float64\n",
      " 35  DC270a  64796 non-null  int64  \n",
      " 36  DC109   64796 non-null  float64\n",
      " 37  DC142a  64796 non-null  float64\n",
      " 38  DC201   64796 non-null  int64  \n",
      "dtypes: float64(33), int64(6)\n",
      "memory usage: 19.8 MB\n"
     ]
    }
   ],
   "source": [
    "# gather information about data attribute\n",
    "data.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dari data di atas, dapat dilihat bahwa semua data bertipe data flloat/integer, dan label bertipe data string."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cari informasi apakah ada data yang bernilai null/kosong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DC024     0\n",
       "DC025     0\n",
       "DC205     0\n",
       "DC206     0\n",
       "DC207     0\n",
       "DC208     0\n",
       "DC209     0\n",
       "DC210     0\n",
       "DC211     0\n",
       "DC212     0\n",
       "DC213     0\n",
       "DC214     0\n",
       "DC215     0\n",
       "DC216     0\n",
       "DC217     0\n",
       "DC219     0\n",
       "DC220     0\n",
       "DC226     0\n",
       "DC230a    0\n",
       "DC230b    0\n",
       "DC232     0\n",
       "DC232b    0\n",
       "DC235     0\n",
       "DC237     0\n",
       "DC237a    0\n",
       "DC237b    0\n",
       "DC237c    0\n",
       "DC237d    0\n",
       "DC237e    0\n",
       "DC237f    0\n",
       "DC241     0\n",
       "DC242     0\n",
       "DC244     0\n",
       "DC246     0\n",
       "DC252     0\n",
       "DC270a    0\n",
       "DC109     0\n",
       "DC142a    0\n",
       "DC201     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cari korelasi tiap atribut dengan pandas corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((51836, 38), (51836,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Split dataset menjadi training dan testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(data.drop('DC201',axis=1),data['DC201'],test_size=0.2)\n",
    "x_train.shape,y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([51836, 38]), torch.Size([51836]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test=torch.Tensor(x_train.values),torch.Tensor(x_test.values),torch.Tensor(y_train.values),torch.Tensor(y_test.values)\n",
    "x_train.shape,y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 1,  ..., 1, 0, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train,y_test=y_train.to(int),y_test.to(int)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create class model\n",
    "class Baseline(nn.Module):\n",
    "    def __init__(self,input_shape:int=4,output_shape:int=3) -> None:\n",
    "        super().__init__()\n",
    "        self.layer=nn.Sequential(\n",
    "            nn.Linear(in_features=input_shape,\n",
    "                      out_features=output_shape),\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        return self.layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Baseline(input_shape=x_train.shape[1],output_shape=2)\n",
    "#setup loss function\n",
    "loss_fn=nn.BCELoss()\n",
    "#setup optimizer\n",
    "optimizer=torch.optim.SGD(params=model.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "device='cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model:nn.Module,\n",
    "               dataloader:torch.utils.data.DataLoader,\n",
    "               loss_fn:nn.Module,\n",
    "               accuracy_fn,\n",
    "               optimizer:torch.optim.Optimizer,\n",
    "               device:torch.device=device\n",
    "               ):\n",
    "    train_acc,train_loss=0,0\n",
    "    # iterate each batch\n",
    "    for batch,(X,y) in enumerate(dataloader):\n",
    "        X,y=X.to(device),y.to(device)\n",
    "    \n",
    "        # Forward pass\n",
    "        y_pred=model(X)\n",
    "        # calculate the loss\n",
    "        loss=loss_fn(y_pred,y)\n",
    "        train_loss+=loss.item()\n",
    "        train_acc+=accuracy_fn(y_true=y,y_pred=y_pred.argmax(dim=1))\n",
    "\n",
    "        # Optimizer zero grad\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Loss backward step\n",
    "        loss.backward()\n",
    "\n",
    "        # optimizer step\n",
    "        optimizer.step()\n",
    "    train_loss=train_loss/len(dataloader)\n",
    "    train_acc=train_acc/len(dataloader)\n",
    "    print(f' Train Accuracy : {train_acc}\\n Train Loass : {train_loss}')\n",
    "    return train_acc,train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(model:nn.Module,\n",
    "              dataloader:torch.utils.data.DataLoader,\n",
    "              loss_fn:nn.Module,\n",
    "              accuracy_fn,\n",
    "              device:torch.device=device):\n",
    "    test_acc, test_loss=0,0\n",
    "    with torch.inference_mode():\n",
    "        for X,y in dataloader:\n",
    "            X,y=X.to(device),y.to(device)\n",
    "            y_pred=model()\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader=DataLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Using a target size (torch.Size([51836])) that is different to the input size (torch.Size([51836, 2])) is deprecated. Please ensure they have the same size.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m     10\u001b[0m y_pred\u001b[39m=\u001b[39mmodel(x_train)\n\u001b[1;32m---> 11\u001b[0m loss\u001b[39m=\u001b[39mloss_fn(y_pred,y_train)\n\u001b[0;32m     12\u001b[0m loss_value\u001b[39m=\u001b[39mloss\u001b[39m.\u001b[39mitem()\n\u001b[0;32m     13\u001b[0m train_loss\u001b[39m.\u001b[39mappend(loss_value)\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\loss.py:619\u001b[0m, in \u001b[0;36mBCELoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 619\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mbinary_cross_entropy(\u001b[39minput\u001b[39;49m, target, weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction)\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\functional.py:3089\u001b[0m, in \u001b[0;36mbinary_cross_entropy\u001b[1;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m   3087\u001b[0m     reduction_enum \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mget_enum(reduction)\n\u001b[0;32m   3088\u001b[0m \u001b[39mif\u001b[39;00m target\u001b[39m.\u001b[39msize() \u001b[39m!=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize():\n\u001b[1;32m-> 3089\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   3090\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUsing a target size (\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m) that is different to the input size (\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m) is deprecated. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   3091\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPlease ensure they have the same size.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(target\u001b[39m.\u001b[39msize(), \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize())\n\u001b[0;32m   3092\u001b[0m     )\n\u001b[0;32m   3094\u001b[0m \u001b[39mif\u001b[39;00m weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   3095\u001b[0m     new_size \u001b[39m=\u001b[39m _infer_size(target\u001b[39m.\u001b[39msize(), weight\u001b[39m.\u001b[39msize())\n",
      "\u001b[1;31mValueError\u001b[0m: Using a target size (torch.Size([51836])) that is different to the input size (torch.Size([51836, 2])) is deprecated. Please ensure they have the same size."
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "EPOCHS=10\n",
    "train_acc=[]\n",
    "test_acc=[]\n",
    "train_loss=[]\n",
    "test_loss=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
